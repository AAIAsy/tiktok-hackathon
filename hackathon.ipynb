{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590f22ef",
   "metadata": {},
   "source": [
    "# Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e9c6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, concat_ws, rand, sum, when, isnull, count, isnan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29fa5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Hackathon\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\", \"16G\") \\\n",
    "        .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "        .config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    "        .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
    "        .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:5.5.0\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86fb8052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pathing_review = \"datasets/review_data/\"\n",
    "arr = np.array(os.listdir(pathing_review))\n",
    "reviewData_files = pathing_review + arr\n",
    "\n",
    "pathing_metadata = \"datasets/review_metadata/\"\n",
    "arr = np.array(os.listdir(pathing_metadata))\n",
    "reviewMetadata_files = pathing_metadata + arr\n",
    "\n",
    "df_review = spark.read.json(list(reviewData_files)).dropna(subset=\"text\").drop_duplicates()\n",
    "df_metadata = spark.read.json(list(reviewMetadata_files)).dropna(subset=\"category\").drop_duplicates().withColumnRenamed(\"name\", \"business_name\").select([\"gmap_id\", \"category\", \"business_name\"])\n",
    "\n",
    "df_joined = df_review.join(df_metadata, on=\"gmap_id\", how=\"inner\").withColumn(\"category_str\", concat_ws(\", \", col(\"category\"))).withColumn(\"random_order\", rand()).orderBy(\"random_order\").drop(\"random_order\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cab35bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gmap_id: string (nullable = true)\n",
      " |-- category: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- business_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_metadata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc3a07c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gmap_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- pics: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- url: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- resp: struct (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- time: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad4d2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gmap_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- pics: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- url: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- resp: struct (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- time: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- category: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- business_name: string (nullable = true)\n",
      " |-- category_str: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ec83cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, count, size, trim, round\n",
    "from pyspark.sql.types import StringType, FloatType, DoubleType, ArrayType, MapType\n",
    "\n",
    "# 1) Drop unwanted columns\n",
    "df_filtered = df_joined.drop(\"pics\", \"resp\", \"time\", \"category\", \"user_id\")\n",
    "\n",
    "# 2) Build a \"is missing\" condition per column based on its data type\n",
    "missing_conds = []\n",
    "for f in df_filtered.schema.fields:\n",
    "    c = col(f.name)\n",
    "    dt = f.dataType\n",
    "\n",
    "    if isinstance(dt, (FloatType, DoubleType)):\n",
    "        # floats/doubles: NULL or NaN\n",
    "        cond = c.isNull() | c.isnan()\n",
    "    elif isinstance(dt, StringType):\n",
    "        # strings: NULL or empty after trim\n",
    "        cond = c.isNull() | (trim(c) == \"\")\n",
    "    elif isinstance(dt, (ArrayType, MapType)):\n",
    "        # arrays/maps: NULL or empty\n",
    "        cond = c.isNull() | (size(c) == 0)\n",
    "    else:\n",
    "        # ints/longs/booleans/date/timestamp/structs: only NULL\n",
    "        cond = c.isNull()\n",
    "\n",
    "    missing_conds.append(count(when(cond, True)).alias(f.name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cc7dd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:====================================================>   (13 + 1) / 14]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+------+----+-------------+------------+\n",
      "|gmap_id|name|rating|text|business_name|category_str|\n",
      "+-------+----+------+----+-------------+------------+\n",
      "|0      |0   |0     |0   |0            |0           |\n",
      "+-------+----+------+----+-------------+------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "missing_counts = df_filtered.select(missing_conds)\n",
    "missing_counts.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b014d8d",
   "metadata": {},
   "source": [
    "### Some reviews have translation, we only need English ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e1e7db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 24:=========================================>              (17 + 6) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                text|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                        (Translated by Google) Good fast service\\n\\n(Original)\\nBuen servicio r√°pido|\n",
      "|(Translated by Google) They do not want to sell carnitas with lots of fat. I kick the compass.\\n\\...|\n",
      "|(Translated by Google) It's worth it even if it's retired.\\n\\n(Original)\\nVale la pena aunque est...|\n",
      "|(Translated by Google) I was here in the morning here at Rapid Wash Laundry and it is heat is alm...|\n",
      "|                                      (Translated by Google) Very good...\\n\\n(Original)\\nMuy bien...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_joined.filter(df_joined.text.contains(\"(Translated by Google)\")).select(\"text\").show(5, truncate=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1209433",
   "metadata": {},
   "source": [
    "### Some reviews have many spacings, remove spacings for one-line reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e636a433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 30:================================================>       (20 + 3) / 23]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+\n",
      "|                                                                                                text|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "|Lake filled with fish, actually a little hilly, plenty of room to walk and wander.  Was a nice br...|\n",
      "|                        (Translated by Google) Good fast service\\n\\n(Original)\\nBuen servicio r√°pido|\n",
      "|Nice people, but can't sit down. Long long line at drive through.  Food was cold, and not too goo...|\n",
      "|(Translated by Google) They do not want to sell carnitas with lots of fat. I kick the compass.\\n\\...|\n",
      "|(Translated by Google) It's worth it even if it's retired.\\n\\n(Original)\\nVale la pena aunque est...|\n",
      "+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_joined.filter(F.col(\"text\").rlike(\"\\n\")).select(\"text\").show(5, truncate=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ee00a06a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing (Translated by Google) prefix and (Original) languages to get the English reviews \n",
    "# Removing all newlines for one-lined reviews\n",
    "# Removing quotation marks\n",
    "\n",
    "df_joined = df_joined.withColumn(\n",
    "    \"text\",\n",
    "    F.when(\n",
    "        F.col(\"text\").contains(\"(Translated by Google)\"),\n",
    "        # extract the English text, remove newlines, remove quotes\n",
    "        F.regexp_replace(\n",
    "            F.regexp_replace(\n",
    "                F.regexp_extract(F.col(\"text\"), r\"\\(Translated by Google\\)\\s*([^\\n]+)\", 1),\n",
    "                r\"\\n+\", \" \"\n",
    "            ),\n",
    "            r\"\\\"\", \"\"\n",
    "        )\n",
    "    ).otherwise(\n",
    "        # for rows without Google Translate tag, remove newlines and quotes\n",
    "        F.regexp_replace(\n",
    "            F.regexp_replace(F.col(\"text\"), r\"\\n+\", \" \"),\n",
    "            r\"\\\"\", \"\"\n",
    "        )\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7644fc11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning::Spark Session already created, some configs may not take.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/30 11:32:45 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "spark_nlp = sparknlp.start(apple_silicon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b56c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Document Assembler\n",
    "# -------------------------------\n",
    "customer_review = DocumentAssembler() \\\n",
    "    .setInputCol(\"text\") \\\n",
    "    .setOutputCol(\"customer_review\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Tokenizer\n",
    "# -------------------------------\n",
    "customer_review_token = Tokenizer() \\\n",
    "    .setInputCols([\"customer_review\"]) \\\n",
    "    .setOutputCol(\"customer_review_token\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Spell Checker\n",
    "# -------------------------------\n",
    "customer_review_spell_checker = NorvigSweetingModel.pretrained() \\\n",
    "    .setInputCols([\"customer_review_token\"]) \\\n",
    "    .setOutputCol(\"customer_review_corrected\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Normalizer (lowercasing, clean text)\n",
    "# -------------------------------\n",
    "customer_review_normalizer = Normalizer() \\\n",
    "    .setInputCols([\"customer_review_corrected\"]) \\\n",
    "    .setOutputCol(\"customer_review_normalized\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. StopWords Cleaner\n",
    "# -------------------------------\n",
    "customer_review_stopwordsCleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"customer_review_normalized\"]) \\\n",
    "    .setOutputCol(\"customer_review_cleaned\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Lemmatizer\n",
    "# -------------------------------\n",
    "customer_review_lemma = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols([\"customer_review_token\"]) \\\n",
    "    .setOutputCol(\"customer_review_lemma\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Word Embeddings (GloVe)\n",
    "# -------------------------------\n",
    "glove_embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\") \\\n",
    "    .setInputCols([\"customer_review_token\", \"customer_review\"]) \\\n",
    "    .setOutputCol(\"word_embeddings\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Sentence Embeddings (average pooling)\n",
    "# -------------------------------\n",
    "sentence_embeddings = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"customer_review\", \"word_embeddings\"]) \\\n",
    "    .setOutputCol(\"customer_review_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Embeddings Finisher (convert to Spark vector/array)\n",
    "# -------------------------------\n",
    "customer_review_finisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"customer_review_embeddings\"]) \\\n",
    "    .setOutputCols([\"customer_review_vector\"]) \\\n",
    "    .setOutputAsVector(True) \\\n",
    "    .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7d2008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# 1. Document Assembler\n",
    "# -------------------------------\n",
    "business_category = DocumentAssembler() \\\n",
    "    .setInputCol(\"category_str\") \\\n",
    "    .setOutputCol(\"business_category\")\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Tokenizer\n",
    "# -------------------------------\n",
    "business_category_token = Tokenizer() \\\n",
    "    .setInputCols([\"business_category\"]) \\\n",
    "    .setOutputCol(\"business_category_token\")\n",
    "\n",
    "# -------------------------------\n",
    "# 3. Spell Checker\n",
    "# -------------------------------\n",
    "business_category_spell_checker = NorvigSweetingModel.pretrained() \\\n",
    "    .setInputCols([\"business_category_token\"]) \\\n",
    "    .setOutputCol(\"business_category_corrected\")\n",
    "\n",
    "# -------------------------------\n",
    "# 4. Normalizer (lowercasing, clean text)\n",
    "# -------------------------------\n",
    "business_category_normalizer = Normalizer() \\\n",
    "    .setInputCols([\"business_category_corrected\"]) \\\n",
    "    .setOutputCol(\"business_category_normalized\") \\\n",
    "    .setLowercase(True)\n",
    "\n",
    "# -------------------------------\n",
    "# 5. StopWords Cleaner\n",
    "# -------------------------------\n",
    "business_category_stopwordsCleaner = StopWordsCleaner() \\\n",
    "    .setInputCols([\"business_category_normalized\"]) \\\n",
    "    .setOutputCol(\"business_category_cleaned\")\n",
    "\n",
    "# -------------------------------\n",
    "# 6. Lemmatizer\n",
    "# -------------------------------\n",
    "business_category_lemma = LemmatizerModel.pretrained() \\\n",
    "    .setInputCols([\"business_category_token\"]) \\\n",
    "    .setOutputCol(\"business_category_lemma\")\n",
    "\n",
    "# -------------------------------\n",
    "# 7. Word Embeddings (GloVe)\n",
    "# -------------------------------\n",
    "business_category_glove_embeddings = WordEmbeddingsModel.pretrained(\"glove_100d\") \\\n",
    "    .setInputCols([\"business_category_token\", \"business_category\"]) \\\n",
    "    .setOutputCol(\"word_embeddings\")\n",
    "\n",
    "# -------------------------------\n",
    "# 8. Sentence Embeddings (average pooling)\n",
    "# -------------------------------\n",
    "business_category_sentence_embeddings = SentenceEmbeddings() \\\n",
    "    .setInputCols([\"business_category\", \"word_embeddings\"]) \\\n",
    "    .setOutputCol(\"business_category_embeddings\") \\\n",
    "    .setPoolingStrategy(\"AVERAGE\")\n",
    "\n",
    "# -------------------------------\n",
    "# 9. Embeddings Finisher (convert to Spark vector/array)\n",
    "# -------------------------------\n",
    "business_category_finisher = EmbeddingsFinisher() \\\n",
    "    .setInputCols([\"business_category_embeddings\"]) \\\n",
    "    .setOutputCols([\"business_category_vector\"]) \\\n",
    "    .setOutputAsVector(True) \\\n",
    "    .setCleanAnnotations(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "109b9337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both into one pipeline\n",
    "pipeline = Pipeline(stages=[\n",
    "    # --- Review branch ---\n",
    "    customer_review,\n",
    "    customer_review_token,\n",
    "    customer_review_spell_checker,\n",
    "    customer_review_normalizer,\n",
    "    customer_review_stopwordsCleaner,\n",
    "    customer_review_lemma,\n",
    "    glove_embeddings,\n",
    "    sentence_embeddings,\n",
    "    customer_review_finisher,\n",
    "\n",
    "    # --- Business category branch ---\n",
    "    business_category,\n",
    "    business_category_token,\n",
    "    business_category_spell_checker,\n",
    "    business_category_normalizer,\n",
    "    business_category_stopwordsCleaner,\n",
    "    business_category_lemma,\n",
    "    business_category_glove_embeddings,\n",
    "    business_category_sentence_embeddings,\n",
    "    business_category_finisher\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c74523f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pipeline.fit(df_joined).transform(df_joined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20e1de42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 46:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-RECORD 0--------------------------------------------------------------------\n",
      " text                   | Lake filled with fish, actually a little hilly,... \n",
      " customer_review_vector | [[-0.10794750601053238,0.2577876150608063,0.312... \n",
      "-RECORD 1--------------------------------------------------------------------\n",
      " text                   | Hot and fresh ü§©                                   \n",
      " customer_review_vector | [[-0.5256632566452026,0.3383975028991699,0.0488... \n",
      "-RECORD 2--------------------------------------------------------------------\n",
      " text                   | Always a long line, always busy                    \n",
      " customer_review_vector | [[-0.21003000438213348,0.2001621276140213,0.118... \n",
      "-RECORD 3--------------------------------------------------------------------\n",
      " text                   | Love the food                                      \n",
      " customer_review_vector | [[0.018898671492934227,0.41114330291748047,0.51... \n",
      "-RECORD 4--------------------------------------------------------------------\n",
      " text                   | Great deals                                        \n",
      " customer_review_vector | [[0.40161198377609253,0.33251500129699707,0.316... \n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.select(\"text\", \"customer_review_vector\").show(5, truncate=50, vertical=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5802c6",
   "metadata": {},
   "source": [
    "### Cosine similarity between review and business category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33b56449",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(v1, v2):\n",
    "    if v1 is None or v2 is None:\n",
    "        return None\n",
    "    a = np.asarray(v1, dtype=float)\n",
    "    b = np.asarray(v2, dtype=float)\n",
    "\n",
    "    # squeeze 1xN / Nx1 or nested singletons to 1-D\n",
    "    if a.ndim > 1:\n",
    "        a = a.reshape(-1)\n",
    "    if b.ndim > 1:\n",
    "        b = b.reshape(-1)\n",
    "\n",
    "    na = np.linalg.norm(a)\n",
    "    nb = np.linalg.norm(b)\n",
    "    if na == 0 or nb == 0:\n",
    "        return 0.0\n",
    "    return float(np.dot(a, b) / (na * nb))\n",
    "\n",
    "cosine_sim_udf = udf(cosine_similarity, DoubleType())\n",
    "\n",
    "result = result.withColumn(\n",
    "    \"cosine_similarity\",\n",
    "    cosine_sim_udf(\"customer_review_vector\", \"business_category_vector\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f976146e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 68:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+------------------+\n",
      "|                                                                                   business_category|                                                                                                text| cosine_similarity|\n",
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+------------------+\n",
      "|[{document, 0, 122, Equipment rental agency, Lawn equipment rental service, Party equipment renta...|Told me on the phone the equipment would fit in my car and could be operated by one person.  I do...|0.7935632383400323|\n",
      "|[{document, 0, 75, Latin American restaurant, Bar, Live music venue, Lounge, Mexican restaurant, ...|Excellent place to have a good time .... üíØ% recommended üåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåüüåü...|0.7938755145496981|\n",
      "|                                          [{document, 0, 15, Amusement center, {sentence -> 0}, []}]|                This was a ton of fun. I would definitely recommend trying it out if you never have.|0.5132572559371459|\n",
      "|[{document, 0, 71, Restaurant, American restaurant, Breakfast restaurant, Family restaurant, {sen...|Food was great service was spectacular was a lil cold in there and our server lowered temp to com...|0.7781005541808532|\n",
      "|                     [{document, 0, 36, Pizza restaurant, Delivery Restaurant, {sentence -> 0}, []}]|                                                                                     Way over priced|0.6722633199490947|\n",
      "+----------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.select(\"business_category\", \"text\", \"cosine_similarity\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840ee801",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f2cafaa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "# Make sure types are friendly\n",
    "result = (result\n",
    "          .withColumn(\"rating\", F.col(\"rating\").cast(\"double\"))\n",
    "          .withColumn(\"text_nn\", F.coalesce(F.col(\"text\"), F.lit(\"\"))))  # avoid nulls for NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.base import DocumentAssembler, Finisher\n",
    "from sparknlp.annotator import Tokenizer, ViveknSentimentModel\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "document = DocumentAssembler().setInputCol(\"text_nn\").setOutputCol(\"doc\")\n",
    "token    = Tokenizer().setInputCols([\"doc\"]).setOutputCol(\"tok\")\n",
    "sent     = ViveknSentimentModel.pretrained().setInputCols([\"doc\",\"tok\"]).setOutputCol(\"sentiment\")\n",
    "finish   = Finisher().setInputCols([\"sentiment\"]).setOutputCols([\"sentiment_label\"]).setOutputAsArray(True)\n",
    "\n",
    "sent_pl  = Pipeline(stages=[document, token, sent, finish])\n",
    "sent_m   = sent_pl.fit(result)\n",
    "\n",
    "scored = sent_m.transform(result)\n",
    "\n",
    "# Map to {-1,0,+1}\n",
    "scored = (scored\n",
    "  .withColumn(\"sentiment_str\", F.element_at(\"sentiment_label\", 1))\n",
    "  .withColumn(\"sentiment_num\",\n",
    "              F.when(F.col(\"sentiment_str\")==\"positive\", 1.0)\n",
    "               .when(F.col(\"sentiment_str\")==\"negative\", -1.0)\n",
    "               .otherwise(0.0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eebe67",
   "metadata": {},
   "source": [
    "### Compare sentiment and vs star rating (for mismatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4ca4dc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1..5 ‚Üí [-1,+1]\n",
    "scored = scored.withColumn(\"rating_norm\", (F.col(\"rating\") - 3.0) / 2.0)\n",
    "\n",
    "# Text vs star disagreement\n",
    "scored = scored.withColumn(\"sentiment_rating_gap\", F.col(\"sentiment_num\") - F.col(\"rating_norm\"))\n",
    "scored = scored.withColumn(\"mismatch_flag\", F.abs(F.col(\"sentiment_rating_gap\")) >= F.lit(0.8))  # tune\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94912405",
   "metadata": {},
   "source": [
    "### ‚ÄúNon-visitor rant‚Äù heuristic (combine clues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a11afbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nonvisit_rx = r\"\"\"(?i)\\b(\n",
    "    never\\s+been|haven'?t\\s+been|didn'?t\\s+visit|did\\s+not\\s+visit|\n",
    "    phone\\s+call|called\\s+(them|store)|left\\s+voicemail|email(ed)?|\n",
    "    website|online\\s+(order|booking|application)|\n",
    "    recruiter|hiring|hr|application\\s+process|\n",
    "    delivery\\s+app|uber\\s+eats|doordash|grab\\s+food\n",
    ")\\b\"\"\"\n",
    "\n",
    "scored = (scored\n",
    "  .withColumn(\"char_len\", F.length(\"text_nn\"))\n",
    "  .withColumn(\"excl_count\", F.size(F.split(F.regexp_replace(F.col(\"text_nn\"), r\"[^!]\", \"\"), \"\")))\n",
    "  .withColumn(\"caps_ratio\",\n",
    "              F.length(F.regexp_replace(F.col(\"text_nn\"), r\"[a-z]\", \"\")) /\n",
    "              (F.col(\"char_len\") + F.lit(1)))\n",
    "  .withColumn(\"nonvisit_clues\", F.col(\"text_nn\").rlike(nonvisit_rx))\n",
    ")\n",
    "\n",
    "# Strong negative + low topicality (cosine) + clues or shouty/short\n",
    "scored = scored.withColumn(\n",
    "    \"possible_nonvisitor_rant\",\n",
    "    (F.col(\"sentiment_num\") <= -0.5) &\n",
    "    (F.col(\"cosine_similarity\") < 0.25) &\n",
    "    (F.col(\"nonvisit_clues\") | (F.col(\"char_len\") < 40) | (F.col(\"excl_count\") >= 3))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6539b219",
   "metadata": {},
   "source": [
    "### Low-quality / spam / off-topic flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "55fe6a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_rx = r\"(?i)\\b(whatsapp|http[s]?://|www\\.|promo|discount code|coupon|call\\s+\\d{3,}|\\+?\\d{7,})\\b\"\n",
    "irrelevant_rx = r\"(?i)\\b(politics|election|government|visa|immigration|job application|recruiter|hiring)\\b\"\n",
    "\n",
    "scored = (scored\n",
    "  .withColumn(\"has_link_or_phone\", F.col(\"text_nn\").rlike(spam_rx))\n",
    "  .withColumn(\"irrelevant_general\", F.col(\"text_nn\").rlike(irrelevant_rx))\n",
    "  .withColumn(\"low_quality_flag\", F.col(\"has_link_or_phone\") | F.col(\"irrelevant_general\"))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345700a9",
   "metadata": {},
   "source": [
    "### One score to triage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36787048",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored = scored.withColumn(\n",
    "    \"flag_score\",\n",
    "    (F.when(F.col(\"possible_nonvisitor_rant\"), 3).otherwise(0)) +\n",
    "    (F.when(F.col(\"low_quality_flag\"),        2).otherwise(0)) +\n",
    "    (F.when(F.col(\"mismatch_flag\"),           1).otherwise(0)) +\n",
    "    (F.when(F.col(\"cosine_similarity\") < 0.15,1).otherwise(0))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4fb4e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_cols = [\"gmap_id\",\"business_name\",\"category_str\",\"rating\",\"rating_norm\",\n",
    "             \"sentiment_str\",\"sentiment_num\",\"cosine_similarity\",\n",
    "             \"sentiment_rating_gap\",\"mismatch_flag\",\n",
    "             \"nonvisit_clues\",\"low_quality_flag\",\"possible_nonvisitor_rant\",\n",
    "             \"flag_score\",\"text_nn\"]\n",
    "\n",
    "final = scored.select(*keep_cols).persist(StorageLevel.MEMORY_AND_DISK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1e36f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e130c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A) Top suspicious\n",
    "final.orderBy(F.desc(\"flag_score\")).show(20, truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cea87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B) Clear mismatches\n",
    "final.filter(F.col(\"mismatch_flag\")).select(\"rating\",\"sentiment_str\",\"sentiment_rating_gap\",\"text_nn\") \\\n",
    "     .show(10, truncate=120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dade2d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# C) Category rollups\n",
    "final.groupBy(\"category_str\").agg(\n",
    "    F.count(\"*\").alias(\"n\"),\n",
    "    F.avg(\"rating\").alias(\"avg_rating\"),\n",
    "    F.avg(\"sentiment_num\").alias(\"avg_sentiment\"),\n",
    "    F.avg(\"cosine_similarity\").alias(\"avg_cosine\")\n",
    ").orderBy(F.desc(\"n\")).show(20, truncate=80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv_hackathon",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
