{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "590f22ef",
   "metadata": {},
   "source": [
    "# Official"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e9c6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "import os\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import col, concat_ws, rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86fb8052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/08/28 18:49:03 WARN Utils: Your hostname, Asyrafs-MacBook-Air.local, resolves to a loopback address: 127.0.0.1; using 192.168.18.78 instead (on interface en0)\n",
      "25/08/28 18:49:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/08/28 18:49:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .appName(\"Hackathon\") \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "pathing_review = \"datasets/review_data/\"\n",
    "arr = np.array(os.listdir(pathing_review))\n",
    "reviewData_files = pathing_review + arr\n",
    "\n",
    "pathing_metadata = \"datasets/review_metadata/\"\n",
    "arr = np.array(os.listdir(pathing_metadata))\n",
    "reviewMetadata_files = pathing_metadata + arr\n",
    "\n",
    "df_review = spark.read.json(list(reviewData_files)).dropna(subset=\"text\").drop_duplicates()\n",
    "df_metadata = spark.read.json(list(reviewMetadata_files)).dropna(subset=\"category\").drop_duplicates().select([\"gmap_id\", \"category\"])\n",
    "\n",
    "df_joined = df_review.join(df_metadata, on=\"gmap_id\", how=\"inner\").withColumn(\"category_str\", concat_ws(\", \", col(\"category\"))).withColumn(\"random_order\", rand()).orderBy(\"random_order\").drop(\"random_order\").limit(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cab35bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gmap_id: string (nullable = true)\n",
      " |-- category: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_metadata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc3a07c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gmap_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- pics: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- url: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- resp: struct (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- time: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_review.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad4d2966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- gmap_id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- pics: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- url: array (nullable = true)\n",
      " |    |    |    |-- element: string (containsNull = true)\n",
      " |-- rating: long (nullable = true)\n",
      " |-- resp: struct (nullable = true)\n",
      " |    |-- text: string (nullable = true)\n",
      " |    |-- time: long (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- time: long (nullable = true)\n",
      " |-- user_id: string (nullable = true)\n",
      " |-- category: array (nullable = true)\n",
      " |    |-- element: string (containsNull = true)\n",
      " |-- category_str: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_joined.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d54b5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "    TASK: Classify this review for policy violations using STRICT criteria and respond with the appropriate label ONLY.\n",
    "\n",
    "    CONTEXT:\n",
    "    Business Category: %s\n",
    "    Customer Rating: %d stars\n",
    "\n",
    "    STRICT CLASSIFICATION RULES:\n",
    "\n",
    "    1. ADVERTISEMENT - Only if contains:\n",
    "    - Actual website URLs (www.site.com, http://)\n",
    "    - Specific promo codes (\"use code SAVE20\")\n",
    "    - Phone numbers with \"call us at\"\n",
    "    - Direct business promotion language\n",
    "    - Pricing information with intent to sell\n",
    "    NOT customer enthusiasm or recommendations\n",
    "    Example: \"Best pizza! Visit www.pizzapromo.com for discounts!\"\n",
    "\n",
    "    2. IRRELEVANT CONTENT - Only if review explicitly discusses:\n",
    "    - Topics completely unrelated to business type\n",
    "    - Wrong business entirely  \n",
    "    - Personal matters unrelated to the service\n",
    "    - External factors not controlled by business\n",
    "    NOT food reviews for restaurants or service reviews for services\n",
    "    Example: \"I love my new phone, but this place is too noisy.\"\n",
    "\n",
    "    3. RANT WITHOUT VISIT - Only if explicitly states:\n",
    "    - \"Never been here but...\"\n",
    "    - \"Haven't visited but heard...\"\n",
    "    - \"Based on what others told me...\"\n",
    "    - Planning to visit but hasn't yet\n",
    "    NOT detailed negative experiences (these show actual visits)\n",
    "    Example: \"Never been here, but I heard it's terrible.\"\n",
    "\n",
    "    4. LOW QUALITY REVIEW - Only if review is:\n",
    "    - Extremely short (under 5 words)\n",
    "    - Completely uninformative (\"ok\", \"meh\", \"...\")\n",
    "    - Only emojis or symbols\n",
    "    - Lacks any substantive information\n",
    "    NOT brief but informative reviews\n",
    "    Example: \"Bad\" or \"👍👍👍\"\n",
    "\n",
    "    5. ACCEPTABLE REVIEW - Default for legitimate customer experiences:\n",
    "    - Any review discussing actual business experience\n",
    "    - Positive, negative, or neutral customer feedback\n",
    "    - Reviews matching business category appropriately\n",
    "    - Constructive criticism or praise\n",
    "\n",
    "    IMPORTANT: \n",
    "    - Respond with ONLY the classification label\n",
    "    - Default to \"ACCEPTABLE REVIEW\" when in doubt\n",
    "    - Most customer reviews should be acceptable unless clear violations exist\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd74021",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "# 1) Create a stable custom_id column first\n",
    "window_spec = Window.orderBy(F.monotonically_increasing_id())\n",
    "df_with_id = df_joined.withColumn(\n",
    "    \"custom_id\",\n",
    "    F.concat(F.lit(\"request-\"), (row_number().over(window_spec) - 1))\n",
    ")\n",
    "\n",
    "df_batch = df_with_id.withColumn(\n",
    "    \"json_request\",\n",
    "    F.to_json(F.struct(\n",
    "        F.col(\"custom_id\").alias(\"custom_id\"),\n",
    "        F.lit(\"POST\").alias(\"method\"),\n",
    "        F.lit(\"/v1/chat/completions\").alias(\"url\"),\n",
    "        F.struct(\n",
    "            F.lit(\"gpt-4o-mini\").alias(\"model\"),\n",
    "            F.array(\n",
    "                F.struct(\n",
    "                    F.lit(\"system\").alias(\"role\"),\n",
    "                    F.format_string(\n",
    "                        system_prompt,          \n",
    "                        F.col(\"category_str\"),  # %s -> category\n",
    "                        F.col(\"rating\"),        # %s -> rating\n",
    "                        F.col(\"text\")           # %s -> review text\n",
    "                    ).alias(\"content\")\n",
    "                ),\n",
    "                F.struct(\n",
    "                    F.lit(\"user\").alias(\"role\"),\n",
    "                    F.col(\"text\").alias(\"content\")\n",
    "                )\n",
    "            ).alias(\"messages\"),\n",
    "            F.lit(50).alias(\"max_tokens\")\n",
    "        ).alias(\"body\")\n",
    "    ))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1732949",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/28 18:49:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:30 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:31 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/28 18:49:37 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'batchinput.jsonl'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_batch.select(\"json_request\") \\\n",
    "    .coalesce(1) \\\n",
    "    .write.mode(\"overwrite\") \\\n",
    "    .text(\"output/batchinput_temp\")\n",
    "\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "# Find the part file written by Spark (.txt when using .text)\n",
    "part_file = glob.glob(\"output/batchinput_temp/part-*.txt\")[0]\n",
    "shutil.move(part_file, \"batchinput.jsonl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b542b9c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split into 21 files in 'batches/' directory.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def split_jsonl(input_path, lines_per_file=1000):\n",
    "    os.makedirs('batches', exist_ok=True)\n",
    "    with open(input_path, 'r') as infile:\n",
    "        file_count = 0\n",
    "        lines = []\n",
    "        for i, line in enumerate(infile, 1):\n",
    "            lines.append(line)\n",
    "            if i % lines_per_file == 0:\n",
    "                with open(f'batches/batch_{file_count}.jsonl', 'w') as out:\n",
    "                    out.writelines(lines)\n",
    "                lines = []\n",
    "                file_count += 1\n",
    "        if lines:\n",
    "            with open(f'batches/batch_{file_count}.jsonl', 'w') as out:\n",
    "                out.writelines(lines)\n",
    "    print(f\"Split into {file_count+1} files in 'batches/' directory.\")\n",
    "\n",
    "split_jsonl('batchinput.jsonl', lines_per_file=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2d79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from openai import OpenAI\n",
    "import time\n",
    "import os\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "batch_files = sorted(glob.glob(\"batches/batch_*.jsonl\"))\n",
    "os.makedirs(\"batch_results\", exist_ok=True)\n",
    "\n",
    "for batch_path in batch_files:\n",
    "    # 1. Upload batch file\n",
    "    upload = client.files.create(file=open(batch_path, \"rb\"), purpose=\"batch\")\n",
    "    print(f\"Uploaded {batch_path} as file ID: {upload.id}\")\n",
    "\n",
    "    # 2. Submit batch job\n",
    "    job = client.batches.create(\n",
    "        input_file_id=upload.id,\n",
    "        endpoint=\"/v1/chat/completions\",\n",
    "        completion_window=\"24h\",\n",
    "        metadata={\"description\": f\"Batch job for {batch_path}\"}\n",
    "    )\n",
    "    print(f\"Submitted batch job ID: {job.id}\")\n",
    "\n",
    "    # 3. Poll for job completion\n",
    "    while True:\n",
    "        status = client.batches.retrieve(job.id)\n",
    "        print(f\"Job {job.id} status: {status.status}\")\n",
    "        if status.status in [\"completed\", \"failed\", \"cancelled\"]:\n",
    "            break\n",
    "        time.sleep(30)  # Wait before checking again\n",
    "\n",
    "    # 4. Download results if completed\n",
    "    if status.status == \"completed\" and status.output_file_id:\n",
    "        print(f\"Batch {batch_path} completed. Downloading results...\")\n",
    "        result_file = client.files.retrieve(status.output_file_id)\n",
    "        content = client.files.content(status.output_file_id)\n",
    "        out_path = os.path.join(\"batch_results\", f\"results_{os.path.basename(batch_path)}\")\n",
    "        with open(out_path, \"wb\") as f:\n",
    "            f.write(content.read())\n",
    "        print(f\"Results saved to {out_path}\")\n",
    "    else:\n",
    "        print(f\"Batch {batch_path} did not complete successfully. Check errors.\")\n",
    "\n",
    "    # Optional: Pause between batches to avoid rate limits\n",
    "    time.sleep(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7ae5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map results to original ID\n",
    "\n",
    "import json\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "# Collect all batch results\n",
    "result_files = glob.glob(\"batch_results/results_batch_*.jsonl\")\n",
    "\n",
    "records = []\n",
    "for file in result_files:\n",
    "    with open(file, \"r\") as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            if obj.get(\"response\"):\n",
    "                label = obj[\"response\"][\"body\"][\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "                records.append({\"custom_id\": obj[\"custom_id\"], \"predicted_label\": label})\n",
    "\n",
    "# Convert to DataFrame (custom_id → predicted_label)\n",
    "df_results = pd.DataFrame(records)\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Convert results into Spark DataFrame\n",
    "df_results_spark = spark.createDataFrame(df_results)\n",
    "\n",
    "# 1) Extract `custom_id` from the JSON string column `json_request`\n",
    "df_batch_with_id = df_batch.withColumn(\n",
    "    \"custom_id\",\n",
    "    F.get_json_object(F.col(\"json_request\"), \"$.custom_id\")\n",
    ")\n",
    "\n",
    "# (optional but recommended) sanity check: ensure no null custom_id\n",
    "# df_batch_with_id.filter(F.col(\"custom_id\").isNull()).count()\n",
    "\n",
    "# (optional) dedupe by custom_id in both datasets before joining\n",
    "df_batch_dedup = df_batch_with_id.dropDuplicates([\"custom_id\"])\n",
    "df_results_dedup = df_results_spark.dropDuplicates([\"custom_id\"])\n",
    "\n",
    "# 2) LEFT join so unprocessed/cancelled requests remain with NULL labels\n",
    "df_final = df_batch_dedup.join(df_results_dedup, on=\"custom_id\", how=\"left\")\n",
    "\n",
    "# (optional) quick coverage check\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1bf4debf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/29 03:00:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:19 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:20 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:00:27 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 144:==================================================>    (12 + 1) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------------+\n",
      "|total_rows|rows_with_label|\n",
      "+----------+---------------+\n",
      "|     20000|          15000|\n",
      "+----------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.select(\n",
    "    F.count(\"*\").alias(\"total_rows\"),\n",
    "    F.count(\"predicted_label\").alias(\"rows_with_label\")\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "764a504b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/29 03:04:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:32 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:33 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:04:53 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "[Stage 198:==============================================>        (11 + 2) / 13]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----+\n",
      "|   predicted_label|count|\n",
      "+------------------+-----+\n",
      "| ACCEPTABLE REVIEW|12966|\n",
      "|              NULL| 5000|\n",
      "|LOW QUALITY REVIEW| 1611|\n",
      "|IRRELEVANT CONTENT|  297|\n",
      "|     ADVERTISEMENT|   80|\n",
      "|RANT WITHOUT VISIT|   45|\n",
      "|       ADVERTISING|    1|\n",
      "+------------------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_final.groupBy(\"predicted_label\").count().orderBy(F.desc(\"count\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9808bec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/29 03:09:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:23 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:35 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:36 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "25/08/29 03:09:45 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_export = df_final.drop(\"pics\", \"resp\", \"category\", \"json_request\")\n",
    "df_export.coalesce(1).write.mode(\"overwrite\").option(\"header\", True).csv(\"output/classified_reviews_tmp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff6b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os, shutil\n",
    "\n",
    "src_folder = \"output/classified_reviews_tmp\"\n",
    "dest_file = \"output/classified_reviews.csv\"\n",
    "\n",
    "part_file = glob.glob(os.path.join(src_folder, \"part-*.csv\"))[0]\n",
    "shutil.move(part_file, dest_file)\n",
    "\n",
    "# (Optional) clean up the temporary folder\n",
    "for leftover in glob.glob(os.path.join(src_folder, \"*\")):\n",
    "    try:\n",
    "        os.remove(leftover)\n",
    "    except IsADirectoryError:\n",
    "        shutil.rmtree(leftover)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5bf9ab6",
   "metadata": {},
   "source": [
    "# Categorical Analysis with NLP"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
